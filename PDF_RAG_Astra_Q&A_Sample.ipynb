{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnannarayanaswamy/GenAI-Relevance-LLM-demo/blob/main/PDF_RAG_Astra_Q%26A_Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us install the binaries, which are important for this code."
      ],
      "metadata": {
        "id": "LKf9vpCK6a_O"
      },
      "id": "LKf9vpCK6a_O"
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install pandas\n",
        "!python3 -m pip install openai\n",
        "!python3 -m pip install langchain\n",
        "!python3 -m pip install cassandra-driver\n",
        "!python3 -m pip install tiktoken\n",
        "!python3 -m pip install cassio\n",
        "!python3 -m pip install PyPDF\n",
        "\n"
      ],
      "metadata": {
        "id": "T1l52Ibn2voe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78fc2afc-4e8e-477c-abcc-570b387ca495"
      },
      "id": "T1l52Ibn2voe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.344)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.8 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.8)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.68)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: cassandra-driver in /usr/local/lib/python3.10/dist-packages (3.28.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver) (1.16.0)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver) (0.2.1.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Requirement already satisfied: cassio in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: cassandra-driver>=3.28.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (3.28.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (1.23.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from cassio) (2.31.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (1.16.0)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (0.2.1.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver>=3.28.0->cassio) (8.1.7)\n",
            "Requirement already satisfied: PyPDF in /usr/local/lib/python3.10/dist-packages (3.17.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "i5VrBfc51dbl"
      },
      "id": "i5VrBfc51dbl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the packages\n",
        "การนำเข้าแพ็คเกจ"
      ],
      "metadata": {
        "id": "ZOw79kaT6Z6c"
      },
      "id": "ZOw79kaT6Z6c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a7cf50-55e5-4cc2-a891-8cb7e171108c",
      "metadata": {
        "id": "f4a7cf50-55e5-4cc2-a891-8cb7e171108c",
        "outputId": "ecef5dfc-656a-4f7e-fbc3-ce420d247cb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully Imported\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cassandra\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Cassandra\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "print(\"Successfully Imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Completing the AstraDB connections\n",
        "import cassandra\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "def get_astra():\n",
        "    keyspace = 'lab'\n",
        "    table= 'labtable'\n",
        "    cloud_config = {'secure_connect_bundle': '<path to astra secure connect bundle>'}\n",
        "    auth_provider = PlainTextAuthProvider('<your client id>','<your client password>')\n",
        "    cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "    session = cluster.connect()\n",
        "    return session, keyspace\n",
        "\n"
      ],
      "metadata": {
        "id": "mT91Nzle8PFh"
      },
      "id": "mT91Nzle8PFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the PDF load files as Embedding to AstraDB\n",
        "กำลังโหลดไฟล์โหลด PDF เป็นการฝังไปยัง AstraDB"
      ],
      "metadata": {
        "id": "wOQ9e2W27fZq"
      },
      "id": "wOQ9e2W27fZq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b85e1a3-651e-4494-81b0-e39205e14fb1",
      "metadata": {
        "id": "5b85e1a3-651e-4494-81b0-e39205e14fb1",
        "outputId": "7904c078-22af-45f4-c087-00fe22d2a675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 2a5f7bcf-0f64-44f3-952e-3b2eb25f7e78-us-east1.db.astra.datastax.com:29042:bb2b3874-d0a5-4737-8953-999977fe9989. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 2a5f7bcf-0f64-44f3-952e-3b2eb25f7e78-us-east1.db.astra.datastax.com:29042:bb2b3874-d0a5-4737-8953-999977fe9989. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(137623622127568) 2a5f7bcf-0f64-44f3-952e-3b2eb25f7e78-us-east1.db.astra.datastax.com:29042:bb2b3874-d0a5-4737-8953-999977fe9989> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 2a5f7bcf-0f64-44f3-952e-3b2eb25f7e78-us-east1.db.astra.datastax.com:29042:bb2b3874-d0a5-4737-8953-999977fe9989. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded\n"
          ]
        }
      ],
      "source": [
        "#Uploding the pdf with the metadata\n",
        "SOURCE_DIR = \"/content\"\n",
        "FILE_SUFFIX = \".pdf\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=\"<your openai key<>\")\n",
        "    pdf_loaders = [\n",
        "        PyPDFLoader(pdf_name)\n",
        "        for pdf_name in (\n",
        "            f for f in (\n",
        "                os.path.join(SOURCE_DIR, f2)\n",
        "                for f2 in os.listdir(SOURCE_DIR)\n",
        "            )\n",
        "            if os.path.isfile(f)\n",
        "            if f[-len(FILE_SUFFIX):] == FILE_SUFFIX\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # set up the vector store\n",
        "    session, keyspace = get_astra()\n",
        "    vectorstore = Cassandra(\n",
        "        embedding=embeddings,\n",
        "        session=session,\n",
        "        keyspace=keyspace,\n",
        "        table_name=\"firsttable\",\n",
        "    )\n",
        "\n",
        "    # strip and load the docs\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=80,\n",
        "    )\n",
        "    documents = [\n",
        "        doc\n",
        "        for loader in pdf_loaders\n",
        "        for doc in loader.load_and_split(text_splitter=text_splitter)\n",
        "    ]\n",
        "    #\n",
        "    texts, metadatas = zip(*((doc.page_content, doc.metadata) for doc in documents))\n",
        "    vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
        "    index = VectorStoreIndexWrapper(vectorstore=vectorstore)\n",
        "print(\"Uploaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Querying from AstraDB vector store\n",
        "การสืบค้นจากร้านค้าเวกเตอร์ AstraDB"
      ],
      "metadata": {
        "id": "TdxJeBZC8mN1"
      },
      "id": "TdxJeBZC8mN1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91ce671f-0e53-4818-8919-7e4964ad02b3",
      "metadata": {
        "id": "91ce671f-0e53-4818-8919-7e4964ad02b3"
      },
      "outputs": [],
      "source": [
        "QUESTION = 'What is about this document?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65280cea-aeb1-42b2-b4d8-47524dd00ebc",
      "metadata": {
        "id": "65280cea-aeb1-42b2-b4d8-47524dd00ebc",
        "outputId": "a0eb2532-1b15-4aef-f832-34876f9bcbda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0]: \"MIT Technology Review Insights\n",
            "www.technologyreview.com\n",
            "insights@technologyreview.com\"\n",
            "[ 1]: \"architecture has an open-source technology \n",
            "component. Using open source is not mandatory, but \n",
            "Rakuten Card’s Ameen recommends developing initial \n",
            "data pipelines with open-source technologies, because \n",
            "not only does this allow organizations to avoid vendor \n",
            "lock-in, it also lets them develop in-house expertise \n",
            "and establish a baseline for expectations. In addition, \n",
            "whether to use open-source technology will depend \n",
            "on the criticality of the data and the need for support.\"\n"
          ]
        }
      ],
      "source": [
        "matchesMMR = vectorstore.search(QUESTION, search_type='mmr', k=2)\n",
        "for i, doc in enumerate(matchesMMR):\n",
        "    print(f'[{i:2}]: \"{doc.page_content}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3923c3f7-e14d-4e6d-abf9-666e4b09fc59",
      "metadata": {
        "id": "3923c3f7-e14d-4e6d-abf9-666e4b09fc59"
      },
      "outputs": [],
      "source": [
        "matchesSim = vectorstore.search(QUESTION, search_type='similarity', k=5)\n",
        "for i, doc in enumerate(matchesSim):\n",
        "    print(f'[{i:2}]: \"{doc.page_content}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using LLM to answer our queries, we will chose any on below LLM to answer your queries\n"
      ],
      "metadata": {
        "id": "vL2vnx739I8s"
      },
      "id": "vL2vnx739I8s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d74dbd92-3a8b-4631-9b0c-663f3fcaaa85",
      "metadata": {
        "id": "d74dbd92-3a8b-4631-9b0c-663f3fcaaa85",
        "outputId": "a0e24215-b73c-4f89-f7bf-45c081868434"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Your secret for LLM provider \"OpenAI\":  ········\n"
          ]
        }
      ],
      "source": [
        "llmProvider = 'OpenAI'  # 'GCP_VertexAI', 'Azure_OpenAI'\n",
        "from getpass import getpass\n",
        "if llmProvider == 'OpenAI':\n",
        "    apiSecret = getpass(f'Your secret for LLM provider \"{llmProvider}\": ')\n",
        "    os.environ['OPENAI_API_KEY'] = apiSecret\n",
        "elif llmProvider == 'GCP_VertexAI':\n",
        "    # we need a json file\n",
        "    print(f'Please upload your Service Account JSON for the LLM provider \"{llmProvider}\":')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        vertexAIJsonFileTitle = list(uploaded.keys())[0]\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.join(os.getcwd(), vertexAIJsonFileTitle)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'No file uploaded. Please re-run the cell.'\n",
        "        )\n",
        "elif llmProvider == 'Azure_OpenAI':\n",
        "    # a few parameters must be input\n",
        "    apiSecret = input(f'Your API Key for LLM provider \"{llmProvider}\": ')\n",
        "    os.environ['AZURE_OPENAI_API_KEY'] = apiSecret\n",
        "    apiBase = input('The \"Base URL\" for your models (e.g. \"https://YOUR-RESOURCE-NAME.openai.azure.com\"): ')\n",
        "    os.environ['AZURE_OPENAI_API_BASE'] = apiBase\n",
        "    apiLLMDepl = input('The name of your LLM Deployment: ')\n",
        "    os.environ['AZURE_OPENAI_LLM_DEPLOYMENT'] = apiLLMDepl\n",
        "    apiLLMModel = input('The name of your LLM Model (e.g. \"gpt-4\"): ')\n",
        "    os.environ['AZURE_OPENAI_LLM_MODEL'] = apiLLMModel\n",
        "    apiEmbDepl = input('The name for your Embeddings Deployment: ')\n",
        "    os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT'] = apiEmbDepl\n",
        "    apiEmbModel = input('The name of your Embedding Model (e.g. \"text-embedding-ada-002\"): ')\n",
        "    os.environ['AZURE_OPENAI_EMBEDDINGS_MODEL'] = apiEmbModel\n",
        "\n",
        "    # The following is probably not going to change for some time...\n",
        "    os.environ['AZURE_OPENAI_API_VERSION'] = '2023-03-15-preview'\n",
        "else:\n",
        "    raise ValueError('Unknown/unsupported LLM Provider')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b381c89-feb4-4b2b-8b63-09a32c2335cf",
      "metadata": {
        "id": "4b381c89-feb4-4b2b-8b63-09a32c2335cf",
        "outputId": "b92054e6-57bd-439f-bbc2-d0ea36536ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM+embeddings from OpenAI\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# creation of the LLM resources\n",
        "\n",
        "\n",
        "if llmProvider == 'GCP_VertexAI':\n",
        "    from langchain.llms import VertexAI\n",
        "    from langchain.embeddings import VertexAIEmbeddings\n",
        "    llm = VertexAI()\n",
        "    myEmbedding = VertexAIEmbeddings()\n",
        "    print('LLM+embeddings from Vertex AI')\n",
        "elif llmProvider == 'OpenAI':\n",
        "    os.environ['OPENAI_API_TYPE'] = 'open_ai'\n",
        "    from langchain.llms import OpenAI\n",
        "    from langchain.embeddings import OpenAIEmbeddings\n",
        "    llm = OpenAI(temperature=0)\n",
        "    myEmbedding = OpenAIEmbeddings()\n",
        "    print('LLM+embeddings from OpenAI')\n",
        "elif llmProvider == 'Azure_OpenAI':\n",
        "    os.environ['OPENAI_API_TYPE'] = 'azure'\n",
        "    os.environ['OPENAI_API_VERSION'] = os.environ['AZURE_OPENAI_API_VERSION']\n",
        "    os.environ['OPENAI_API_BASE'] = os.environ['AZURE_OPENAI_API_BASE']\n",
        "    os.environ['OPENAI_API_KEY'] = os.environ['AZURE_OPENAI_API_KEY']\n",
        "    from langchain.llms import AzureOpenAI\n",
        "    from langchain.embeddings import OpenAIEmbeddings\n",
        "    llm = AzureOpenAI(temperature=0, model_name=os.environ['AZURE_OPENAI_LLM_MODEL'],\n",
        "                      engine=os.environ['AZURE_OPENAI_LLM_DEPLOYMENT'])\n",
        "    myEmbedding = OpenAIEmbeddings(model=os.environ['AZURE_OPENAI_EMBEDDINGS_MODEL'],\n",
        "                                   deployment=os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT'])\n",
        "    print('LLM+embeddings from Azure OpenAI')\n",
        "else:\n",
        "    raise ValueError('Unknown LLM provider.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3fc9708-6458-47ae-86c5-bd8164a5c5c2",
      "metadata": {
        "id": "a3fc9708-6458-47ae-86c5-bd8164a5c5c2",
        "outputId": "6434a11d-364f-43a4-f5a7-70ddf405713e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " This document is about the terms and conditions of a Health Companion Health Insurance Plan.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(index.query(QUESTION, llm=llm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b4c395-ed2b-4e75-8314-6c0383c24845",
      "metadata": {
        "id": "14b4c395-ed2b-4e75-8314-6c0383c24845",
        "outputId": "c1b897a0-0852-4e94-b50f-7b10db96f080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " This document is about the terms and conditions of a Health Companion Health Insurance Plan.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
        "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
        "retrieverMMR = vectorstore.as_retriever(\n",
        "    search_type='mmr',\n",
        "    search_kwargs={\n",
        "        'k': 4,\n",
        "        # ...\n",
        "    },\n",
        ")\n",
        "# Create a \"RetrievalQA\" chain\n",
        "chainMMR = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retrieverMMR\n",
        ")\n",
        "# Run it and print the results\n",
        "responseMMR = chainMMR.run(QUESTION)\n",
        "print(responseMMR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de6d3d9-f898-4acc-85b5-8a4ed2016a04",
      "metadata": {
        "id": "0de6d3d9-f898-4acc-85b5-8a4ed2016a04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb0b2a84-eaaa-4e01-a3b2-d72648d07785",
      "metadata": {
        "id": "eb0b2a84-eaaa-4e01-a3b2-d72648d07785"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}